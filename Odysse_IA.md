# üåå L'Odyss√©e de l'Intelligence Artificielle : Des Origines Anthropologiques aux Horizons Contemporains <!-- omit in toc -->
_Romuald COURTOIS, 29/08/2025_ 
<br>
<br>
<br>
<br>

# üéØ Objectif <!-- omit in toc -->

Retracer l‚Äô√©volution de l‚Äôintelligence artificielle, depuis les fondements anthropologiques et cognitifs de l‚ÄôHomme jusqu‚Äôaux perspectives futures, afin de comprendre comment la qu√™te d‚Äôoptimisation et de simplification a fa√ßonn√© les outils, les machines et, aujourd‚Äôhui, l‚ÄôIA.

# üîë Id√©e directrice <!-- omit in toc -->

L‚Äôhistoire de l‚ÄôIA est l‚Äôhistoire de l‚Äô_¬´ √©ternel fain√©ant ambitieux ¬ª_ : l‚ÄôHomme, en cherchant √† √©conomiser son √©nergie, a sans cesse invent√© de nouvelles solutions techniques, ouvrant ainsi des possibilit√©s in√©dites. Cette logique d‚Äôextension et de d√©l√©gation culmine dans les technologies d‚Äôintelligence artificielle contemporaines.

# üöÄ Valeur ajout√©e <!-- omit in toc -->

- Approche chronologique et conceptuelle, reliant innovations techniques, contexte culturel et impact soci√©tal.
- Mise en lumi√®re du fil rouge anthropologique : la paresse comme moteur d‚Äôinnovation.
- Ouverture sur les d√©fis futurs : √©thique, gouvernance, durabilit√©.
<br>
<br>

### üí° Th√®se principale : L'intelligence artificielle n'est pas une innovation du XXe si√®cle, mais l'aboutissement de 40 000 ans de recherche humaine pour cr√©er des extensions de nos capacit√©s cognitives et physiques. <!-- omit in toc -->
<br>
<br>
<br>
<br>

# Table des mati√®res <!-- omit in toc -->
- [PARTIE I : Fondations anthropologiques et mythologiques](#partie-i--fondations-anthropologiques-et-mythologiques)
  - [1. L'√©ternel fain√©ant ambitieux : √©conomie d'√©nergie cognitive et paresse cr√©ative](#1-l√©ternel-fain√©ant-ambitieux--√©conomie-d√©nergie-cognitive-et-paresse-cr√©ative)
  - [2. Pr√©histoire \& Antiquit√© : du mythe aux premi√®res machines logiques](#2-pr√©histoire--antiquit√©--du-mythe-aux-premi√®res-machines-logiques)
- [PARTIE II : De la m√©canisation √† la formalisation (800-1750)](#partie-ii--de-la-m√©canisation-√†-la-formalisation-800-1750)
  - [3. Automates m√©di√©vaux et machines logiques](#3-automates-m√©di√©vaux-et-machines-logiques)
  - [4. Renaissance m√©canique et corpus philosophique](#4-renaissance-m√©canique-et-corpus-philosophique)
- [PARTIE III : Rationalisation m√©canique et calcul (1750-1945)](#partie-iii--rationalisation-m√©canique-et-calcul-1750-1945)
  - [5. Automates sophistiqu√©s, r√©volution industrielle et naissance du calcul m√©canique](#5-automates-sophistiqu√©s-r√©volution-industrielle-et-naissance-du-calcul-m√©canique)
  - [6. Tensions fondatrices : crises, alg√®bre, incompl√©tude et formalisations modernes](#6-tensions-fondatrices--crises-alg√®bre-incompl√©tude-et-formalisations-modernes)
- [PARTIE IV : L'√¢ge d'or th√©orique \& av√®nement des machines (1945-1970)](#partie-iv--l√¢ge-dor-th√©orique--av√®nement-des-machines-1945-1970)
  - [7. Math√©maticiens et ing√©nieurs de la computation](#7-math√©maticiens-et-ing√©nieurs-de-la-computation)
  - [8. Naissance officielle de l‚ÄôIA : crit√®res, conf√©rence et premiers programmes](#8-naissance-officielle-de-lia--crit√®res-conf√©rence-et-premiers-programmes)
- [PARTIE V : Cycles d'enthousiasme, hivers et paradigmes √©mergents (1970-2000)](#partie-v--cycles-denthousiasme-hivers-et-paradigmes-√©mergents-1970-2000)
  - [9. Approches symboliques et connexionnistes : premiers antagonismes](#9-approches-symboliques-et-connexionnistes--premiers-antagonismes)
  - [10. Premier hiver de l‚ÄôIA : r√©alit√©s et d√©sillusions (1974‚Äì1980)](#10-premier-hiver-de-lia--r√©alit√©s-et-d√©sillusions-19741980)
  - [11. Renaissance des syst√®mes experts et Mardi noir de l‚ÄôIA (1980‚Äì1987)](#11-renaissance-des-syst√®mes-experts-et-mardi-noir-de-lia-19801987)
  - [12. Deuxi√®me hiver et transition statistique (1987‚Äì1997)](#12-deuxi√®me-hiver-et-transition-statistique-19871997)
- [PARTIE VI : Convergence et synth√®se contemporaine (2000-2025)](#partie-vi--convergence-et-synth√®se-contemporaine-2000-2025)
  - [11. L‚Äô√®re Internet et renaissance du machine learning](#11-l√®re-internet-et-renaissance-du-machine-learning)
  - [12. R√©volution deep learning et √©mergence neuro-symbolique](#12-r√©volution-deep-learning-et-√©mergence-neuro-symbolique)
  - [13. √àre Transformers et explosion g√©n√©rative](#13-√®re-transformers-et-explosion-g√©n√©rative)
  - [14. Course concurrentielle et pi√®ge de Moloch](#14-course-concurrentielle-et-pi√®ge-de-moloch)
- [PARTIE VII : Vers une nouvelle intelligence - La r√©volution Fristonienne](#partie-vii--vers-une-nouvelle-intelligence---la-r√©volution-fristonienne)
  - [15. Karl Friston et le principe de l‚Äô√©nergie libre](#15-karl-friston-et-le-principe-de-l√©nergie-libre)
  - [16. Facteurs humains et IA centr√©e sur l‚Äôhumain](#16-facteurs-humains-et-ia-centr√©e-sur-lhumain)
    - [16.1 Ergonomie cognitive et interfaces adaptatives](#161-ergonomie-cognitive-et-interfaces-adaptatives)
    - [16.2 Lecture des pens√©es par mouvements oculaires](#162-lecture-des-pens√©es-par-mouvements-oculaires)
    - [16.3 Cognition √©nactive et syst√®mes bio-inspir√©s](#163-cognition-√©nactive-et-syst√®mes-bio-inspir√©s)
- [PARTIE VIII : Le√ßons des √©checs et succ√®s technologiques](#partie-viii--le√ßons-des-√©checs-et-succ√®s-technologiques)
  - [17. √âchecs embl√©matiques et analyses critiques](#17-√©checs-embl√©matiques-et-analyses-critiques)
  - [18. Succ√®s instructifs et bonnes pratiques](#18-succ√®s-instructifs-et-bonnes-pratiques)
  - [19. Enjeux cl√©s et perspectives](#19-enjeux-cl√©s-et-perspectives)
- [PARTIE IX : Futurs possibles et imaginaires critiques](#partie-ix--futurs-possibles-et-imaginaires-critiques)
  - [20. Vers l‚ÄôAGI bio-inspir√©e : Active Inference et conscience artificielle](#20-vers-lagi-bio-inspir√©e--active-inference-et-conscience-artificielle)
  - [21. Black Mirror et prospective critique : dystopies et coop√©rations](#21-black-mirror-et-prospective-critique--dystopies-et-coop√©rations)
  - [22. L‚Äôodyss√©e inachev√©e : vers une intelligence augment√©e et collaborative](#22-lodyss√©e-inachev√©e--vers-une-intelligence-augment√©e-et-collaborative)
- [PARTIE X : √âvolution de l‚Äô√©thique de l‚ÄôIA](#partie-x--√©volution-de-l√©thique-de-lia)
  - [23. √âvolution de l‚Äô√©thique de l‚ÄôIA](#23-√©volution-de-l√©thique-de-lia)
- [Conclusion](#conclusion)
- [üìö 8. Bibliographie](#-8-bibliographie)

<br>
<br>
<br>

# PARTIE I : Fondations anthropologiques et mythologiques
## 1. L'√©ternel fain√©ant ambitieux : √©conomie d'√©nergie cognitive et paresse cr√©ative

> *L'√âternel Fain√©ant Ambitieux*
> De l‚Äô√©conomie d‚Äô√©nergie √† l‚Äôextension des possibles

**Le principe d'√©conomie d'√©nergie : une constante anthropologique**

L'histoire de l'intelligence artificielle trouve ses racines les plus profondes dans une caract√©ristique fondamentale de l'esp√®ce humaine : sa tendance naturelle √† l'√©conomie d'√©nergie cognitive. Cette propension, loin d'√™tre un d√©faut moral, constitue un m√©canisme adaptatif essentiel qui a guid√© l'√©volution technologique de l'humanit√© depuis ses origines ([Kahneman, 2011](#kahneman2011)).Le cerveau humain, bien qu'il ne repr√©sente que 2% du poids corporel, consomme pr√®s de 20% de notre √©nergie m√©tabolique totale ([Raichle & Gusnard, 2002](#raichle2022)). 

Des √©tudes r√©centes en neurosciences confirment cette tendance. Cheval et al. (2018) ont d√©montr√© que l‚Äô√©vitement de l‚Äôinactivit√© physique n√©cessite un investissement accru des ressources c√©r√©brales. ‚ÄúNos cerveaux sont c√¢bl√©s pour pr√©f√©rer rester sur le canap√©‚Äù, une caract√©ristique h√©rit√©e de nos anc√™tres chasseurs-cueilleurs pour qui l‚Äô√©conomie d‚Äô√©nergie √©tait vitale pour la survie ([Cheval et al., 2018](#cheval2018)).

**Pr√©histoire lointaine : √âmergence de l‚Äôintelligence (‚àí7 Ma ‚Üí ‚àí300 000 ans)**

<div align="center">
   <img src="images/partie1/bifaces_acheuleens.jpg" alt="Bifaces Acheul√©ens (‚àí1,6 Ma)" style="width: 40%; max-width: 600px;">
</div>

La ‚Äúparesse cr√©ative‚Äù s‚Äôexprime d√®s l‚Äôinvention des premiers outils lithiques. Les choppers oldowayens (‚àí2,7 Ma) et bifaces acheul√©ens (‚àí1,6 Ma) sont autant d‚Äôillustrations de l‚Äôexternalisation technologique d‚Äôune fonction biologique : prolonger la main pour √©conomiser l‚Äôeffort physique direct ([Harmand et al., 2015](#harmand2015)). L‚Äô√©volution vers des outils Levallois plus sophistiqu√©s t√©moigne d‚Äôune anticipation et d‚Äôune planification accrues, toujours guid√©es par la recherche d‚Äôefficacit√© maximale avec un minimum d‚Äôeffort ([Leroi-Gourhan, 1964](#leroi1964)).

**La domestication du feu : premi√®re r√©volution √©nerg√©tique**

Ma√Ætris√© d√®s ‚àí400 000 ans, le feu repr√©sente la premi√®re source d‚Äô√©nergie externe domin√©e par l‚Äôhomme ([Gowlett, 2016](#gowlett2016)). Au-del√† de la cuisson des aliments, il permet de r√©duire l‚Äô√©nergie d√©pens√©e pour la digestion, lib√©rant des ressources m√©taboliques pour le d√©veloppement c√©r√©bral ([Wrangham, 2009](#wrangham2009)). Le feu, en pr√©dig√©rant les aliments, illustre parfaitement la logique de la paresse cr√©ative : utiliser l‚Äô√©nergie externe plut√¥t que celle contenue dans les nutriments.

**Pr√©histoire r√©cente : Explosion symbolique (‚àí300 000 ‚Üí ‚àí10 000 ans)**

<div align="center">
   <img src="images/partie1/lascaux.jpg" alt="Peinture rupestre des Grottes de Lascaux (‚àí1,6 Ma)" style="width: 40%; max-width: 600px;">
</div>

L‚Äô√©mergence du langage r√©sulte √©galement d‚Äôune optimisation √©nerg√©tique. Selon la th√©orie de Huntley et Hayden, les locuteurs adaptent leur articulation pour √™tre compris avec un minimum d‚Äôeffort, un principe d‚Äô‚Äúhypo-articulation‚Äù comparable aux interfaces homme-machine modernes ([Lindblom, 1990](#lindblom1990)). Parall√®lement, l‚Äôart pari√©tal (peinture rupestre) et les premi√®res repr√©sentations symboliques fonctionnent comme des supports externes de m√©moire, lib√©rant la capacit√© cognitive pour d‚Äôautres t√¢ches ([Lewis-Williams, 2002](#lewis2002)).

**N√©olithique : R√©volution technologique (‚àí10 000 ‚Üí ‚àí3 000 ans)**

L‚Äôagriculture et l‚Äô√©levage instaurent une production d‚Äô√©nergie exc√©dentaire, marquant un tournant dans l‚Äôhistoire humaine ([Diamond, 1997](#diamond1997)). L‚Äôinvention de la roue, la traction animale et l‚Äôirrigation illustrent la logique d‚Äôamplification √©nerg√©tique : maximiser les rendements tout en minimisant l‚Äôeffort humain direct. L‚Äô√©criture, n√©e vers ‚àí3 000 ans pour la comptabilit√© des ressources, constitue la forme la plus aboutie d‚Äôexternalisation symbolique des t√¢ches cognitives r√©p√©titives ([Diamond, 1997](#diamond1997)).

**L‚Äôambition par la paresse : extensions des possibles**

La ‚Äúparesse cr√©ative‚Äù n‚Äôest ni vice ni faiblesse, mais moteur fondamental de l‚Äôinnovation. De l‚Äôoutil lithique √† la cuisson du feu, de l‚Äô√©criture √† l‚ÄôIA contemporaine, l‚Äôhumanit√© poursuit une qu√™te constante : lib√©rer ses capacit√©s cr√©atives en confiant les t√¢ches r√©p√©titives √† des syst√®mes externes. L‚Äôintelligence artificielle appara√Æt ainsi comme l‚Äôaboutissement logique d‚Äôune odyss√©e technologique vieille de plusieurs millions d‚Äôann√©es. Cette continuit√© anthropologique √©claire les enjeux actuels non comme des ruptures radicales, mais comme les nouveaux chapitres d‚Äôun m√™me r√©cit, guid√© par le principe de l‚Äô√©conomie d‚Äô√©nergie cognitive.

## 2. Pr√©histoire & Antiquit√© : du mythe aux premi√®res machines logiques

> *"Des dieux forg√®rent les premiers automates, l'homme r√™va de les √©galer"*
> Du mythe √† la machine : gen√®se des intelligences artificielles
> 
> Citation adapt√©e d'Hom√®re, Iliade, XVIII, 376-377, inspir√©e des cr√©ations d'H√©pha√Østos.

**Imaginaires techniques : les premiers "robots" conceptuels**

Bien avant que l'humanit√© ne poss√®de les moyens techniques de cr√©er de v√©ritables automates, l'imaginaire collectif avait d√©j√† con√ßu des √™tres artificiels dot√©s d'intelligence. Cette anticipation mythologique r√©v√®le une constante anthropologique : le d√©sir de cr√©er des auxiliaires automatis√©s pour √©conomiser l'effort humain.

**Talos**, le g√©ant de bronze de la mythologie grecque, constitue l'arch√©type du robot protecteur. Cr√©√© par H√©pha√Østos selon Les Argonautiques d'Apollonius de Rhodes (IIIe si√®cle av. J.-C.), ce colosse automatis√© fait "trois fois par jour le tour de la Cr√®te" pour repousser les envahisseurs ([Apollonius de Rhodes. (s.d.). Argonautiques (IV, 1638‚Äë1648)](#apollonius)). Sa construction r√©v√®le une sophistication conceptuelle remarquable : aliment√© par l'ichor (sang divin) circulant dans une veine unique, il poss√®de un point de d√©faillance unique √† la cheville, pr√©figurant les vuln√©rabilit√©s des syst√®mes informatiques modernes.

Le mythe de Pygmalion et Galat√©e explore une autre dimension : la cr√©ation d'une intelligence artificielle par amour plut√¥t que par utilit√©. Selon Ovide ([Ovide, s.d., X, 243‚Äë297](#ovide)), le sculpteur chypriote fa√ßonne une femme d'ivoire si parfaite qu'elle obtient la vie gr√¢ce √† Aphrodite. Ce r√©cit anticipe les questionnements contemporains sur l'anthropomorphisation des IA et l'attachement √©motionnel aux cr√©atures artificielles, comme l'illustrent aujourd'hui les relations avec les assistants conversationnels.

La tradition h√©bra√Øque offre avec le Golem une vision plus pragmatique de la cr√©ation artificielle. Cette cr√©ature d'argile, anim√©e par l'inscription du mot emet ("v√©rit√©") sur son front, sert de protecteur de la communaut√© juive. Sa d√©sactivation par effacement de la premi√®re lettre (aleph), transformant emet en met ("mort"), pr√©figure les protocoles d'arr√™t des syst√®mes automatis√©s ([Idel, 1990](#idel1990)).

**R√©alisations techniques : H√©ron d'Alexandrie et la m√©canique programmable**

<div align="center">
   <img src="images/partie1/eolipyle.jpg" alt="Eolipyle* (sph√®re √©olienne) d'H√©ron" style="width: 40%; max-width: 600px;">
</div>

L'√âgypte hell√©nistique du Ier si√®cle apr. J.-C. voit na√Ætre les premiers automates v√©ritablement fonctionnels sous l'impulsion d'H√©ron d'Alexandrie. Ses trait√©s *Pneumatica* et *Automata* d√©crivent des m√©canismes sophistiqu√©s utilisant "l'air, la vapeur ou l'eau" comme force motrice, destin√©s √† "susciter l'√©tonnement et l'√©merveillement" ([H√©ron d‚ÄôAlexandrie, s.d.](#heron)).

Les portes automatiques du temple d'H√©ron illustrent parfaitement cette ing√©nierie anticipatrice. Activ√©es par la chaleur d'un feu allum√© sur l'autel, elles s'ouvrent gr√¢ce √† un syst√®me pneumatique sophistiqu√© : l'air chaud dilate l'eau dans une cuve souterraine, cr√©ant une pression qui actionne les m√©canismes d'ouverture. Ce syst√®me r√©v√®le une logique de programmation primitive : une s√©quence pr√©d√©termin√©e d'actions d√©clench√©e par un stimulus externe.

Plus r√©volutionnaires encore, les tr√©pieds automobiles d'H√©ron constituent les premiers v√©hicules programmables de l'histoire. Ces chariots suivent un parcours pr√©d√©fini gr√¢ce √† un "syst√®me de cordes enroul√©es" autour des essieux, pr√©figurant les algorithmes de navigation contemporains. Leur fonctionnement anticipe de deux mill√©naires les principes de la robotique mobile autonome.

L'*√©olipyle* (sph√®re √©olienne) d'H√©ron, premier moteur √† vapeur fonctionnel, d√©montre que l'Antiquit√© poss√©dait les bases th√©oriques de la r√©volution industrielle. Cette "machine √† vapeur ancestrale" restera pourtant sans application pratique, illustrant le d√©calage entre innovation technique et adoption sociale.

**Machine d'Anticyth√®re : premier ordinateur analogique**

<div align="center">
   <img src="images/partie1/anticythere.jpg" alt="M√©canisme d'Anticyth√®re" style="width: 40%; max-width: 600px;">
</div>

D√©couverte en 1901 dans une √©pave au large de l'√Æle grecque d'Anticyth√®re, cette machine de bronze datant du IIe si√®cle av. J.-C. constitue le premier ordinateur analogique de l'histoire. Ses 37 engrenages en bronze permettaient de "calculer avec pr√©cision la position du soleil, de la lune et des plan√®tes" ([Freeth et al., 2021](#freeth2021)).

Les recherches r√©centes de l'University College London ont r√©v√©l√© la sophistication exceptionnelle de ce dispositif. Capable de pr√©dire les √©clipses, les phases lunaires et m√™me les dates des Jeux olympiques, il int√®gre des cycles astronomiques complexes avec une pr√©cision qui "remet en cause toutes nos id√©es pr√©con√ßues sur les capacit√©s technologiques des anciens Grecs" ([Freeth et al., 2021](#freeth2021)).

La machine d'Anticyth√®re r√©v√®le l'existence d'une tradition technologique avanc√©e dans l'Antiquit√© grecque. Son niveau de sophistication ne sera retrouv√© qu'avec les horloges astronomiques m√©di√©vales, pr√®s de 1500 ans plus tard. Elle t√©moigne d'une capacit√© de calcul automatis√© et de pr√©diction qui pr√©figure directement les fonctions des ordinateurs modernes.

**Aristote et les fondements de la logique formelle**

Parall√®lement √† ces innovations techniques, Aristote (384-322 av. J.-C.) pose les bases th√©oriques de la logique formelle dans ses *Premiers Analytiques*. Sa th√©orie du syllogisme constitue le premier syst√®me de *"raisonnement d√©ductif"* formalis√©, √©tablissant des "r√®gles d'inf√©rence formelles dont le caract√®re contraignant rel√®ve de l'√©vidence" ([Aristote, s.d., I, 4](#aristote)).

Le syllogisme aristot√©licien, avec ses trois propositions (deux pr√©misses et une conclusion) articulant trois termes, pr√©figure les structures algorithmiques modernes. Sa formalisation par l'usage de variables (A, B, C) constitue la premi√®re abstraction logique permettant de manipuler des contenus conceptuels ind√©pendamment de leur sens sp√©cifique.

Cette logique formelle √©tablit les fondements de ce qui deviendra, deux mill√©naires plus tard, l'*informatique th√©orique*. Les "r√®gles d'inf√©rence" d'Aristote anticipent les op√©rations bool√©ennes et les syst√®mes de preuve automatis√©e qui constitueront l'ossature de l'intelligence artificielle symbolique.

**Transmission et h√©ritage**

L'Antiquit√© grecque et hell√©nistique l√®gue ainsi √† la post√©rit√© trois √©l√©ments fondamentaux pour le d√©veloppement futur de l'IA :
- des imaginaires techniques (mythes d'automates intelligents), 
- des r√©alisations m√©caniques (automates d'H√©ron, machine d'Anticyth√®re),
- des formalisations logiques (syllogistique aristot√©licienne).

Cette convergence entre imagination, technique et logique constitue la matrice originelle de l'intelligence artificielle. Elle r√©v√®le que le projet d'automatisation de l'intelligence n'est pas une rupture moderne, mais l'aboutissement d'une qu√™te anthropologique mill√©naire : √©conomiser l'√©nergie cognitive humaine en externalisant le raisonnement dans des syst√®mes automatis√©s.

La synth√®se antique de ces trois dimensions - mythologique, technique et logique - √©tablit les fondations conceptuelles sur lesquelles s'√©difiera, pr√®s de deux mill√©naires plus tard, la r√©volution de l'intelligence artificielle contemporaine.

# PARTIE II : De la m√©canisation √† la formalisation (800-1750)

## 3. Automates m√©di√©vaux et machines logiques

> *"Dans l‚Äôeau et la vapeur, jaillit l‚Äôesprit des automates."*
> 
> Citation librement inspir√©e des inventions hydrauliques d‚Äôal-Jazari (1206).

**Al-Jazari et la r√©volution hydraulique programmable**

Au d√©but du XIII·µâ si√®cle, Ab≈´ al- øIzÃÑ Ibn IsmƒÅ øƒ´l al-Jazarƒ´ (1136‚Äì1206) codifie pour la premi√®re fois les proc√©d√©s m√©caniques dans son *KitƒÅb fƒ´ ma ørifat al-·∏•iyal al-handasiyya* (1206). Il y d√©crit plus de cinquante dispositifs, parmi lesquels l‚Äô*horloge-√©l√©phant*, structure monumentale de sept m√®tres anim√©e par des pistons et un vilebrequin coupl√©s √† un r√©servoir hydraulique. Ce m√©canisme, orn√© d‚Äô√©l√©ments symboliques (√©l√©phant, dragon, ph√©nix), illustre une programmation primitive par s√©quences temporelles : chaque heure, des automates serviteurs distribuent rafra√Æchissements selon un cycle pr√©d√©fini, pr√©figurant le concept de routine algorithmique ([al‚ÄëJazarƒ´, 1206](#aljazari1206)).

Outre les horloges, al-Jazari invente des serviteurs m√©caniques d√©livrant boissons ou serviettes, activ√©s par des pressions d‚Äôeau successives. Ces humano√Ødes fluidiques incarnent l‚Äôid√©e d‚Äôune s√©quence d‚Äôactions automatis√©es, o√π chaque √©tape d√©clenche la suivante sans intervention humaine, anticipant les syst√®mes de contr√¥le s√©quentiel modernes ([Hill, 1993](#hill1993)). Ses innovations - machines √† pomper, robinets automatiques, vilebrequins ‚Äì influencent directement l‚Äôing√©nierie hydraulique et m√©canique jusqu‚Äô√† la r√©volution industrielle.

**Llull et la premi√®re machine logique**

Vers 1305, Ramon Llull (1232‚Äì1316) publie l‚ÄôArs Magna, o√π il pr√©sente une ‚Äúmachine de papier‚Äù compos√©e de disques concentriques inscrits de symboles th√©ologiques et philosophiques. En faisant tourner ces disques, l‚Äôutilisateur g√©n√®re toutes les combinaisons conceptuelles possibles pour r√©soudre des questions de foi ou de science. Llull postule l‚Äôexistence d‚Äôun alphabet universel des id√©es, dont l‚Äôordonnancement m√©canique permettrait de prouver ou r√©futer tout √©nonc√© ([Llull, vers 1305](#llull1305)).

Cette formalisation algorithmique du raisonnement constitue le premier jalon de l‚ÄôIA symbolique : la pens√©e comme combinaison de symboles. Llull anticipe la cr√©ation de langages de programmation et de syst√®mes de preuve automatis√©e. Son influence s‚Äô√©tend jusqu‚Äô√† Leibniz, qui reconna√Æt dans l‚Äô*Ars Magna* les pr√©mices de son *calculus ratiocinator* et de son projet de *mathesis universalis*.

**Astrarium : computing m√©canique et mod√©lisation du cosmos**

<div align="center">
   <img src="images/partie2/astarium.jpg" alt="Astrarium de Giovanni Dondi (1330‚Äì1388)" style="width: 30%; max-width: 600px;">
</div>

Au XIV·µâ si√®cle, l‚ÄôEurope savante √©rige les horloges astronomiques en mod√®les de computing m√©canique. L‚Äô*astrarium* de Giovanni Dondi (1330‚Äì1388), construit entre 1365 et 1381 √† Padoue, est une horloge plan√©taire qui indique heure, date, positions du Soleil, de la Lune et des cinq plan√®tes visibles (Mercure, V√©nus, Mars, Jupiter, Saturne) via un r√©seau de 200 engrenages articul√©s ([Dondi, 1365‚Äì1381](#dondi1365)).

Chaque cadran et chaque engrenage traduisent un mod√®le math√©matique du ciel en op√©rations m√©caniques automatiques, simulant le mouvement des astres selon le syst√®me ptol√©m√©en (G√©ocentrisme). Comme le note Lynn White Jr., ces instruments sont ‚Äúmoins des chronom√®tres que des expositions mobiles du cosmos‚Äù. Ils t√©moignent de la conviction m√©di√©vale que la machine peut refl√©ter la structure de l‚Äôunivers, pr√©parant l‚Äôid√©e de simulation num√©rique contemporaine ([White, 1962, p. 122](#white1862)).

## 4. Renaissance m√©canique et corpus philosophique

> *‚ÄúLe m√©canisme n‚Äôest pas l‚Äôennemi de l‚Äô√¢me, mais son meilleur serviteur.‚Äù*
> 
> Inspir√© de Ren√© Descartes, Discours de la m√©thode (1637).

**Scolastique : vers l‚Äôalgorithme du d√©bat intellectuel**

Entre le IX·µâ et le XV·µâ si√®cle, la scolastique codifie le raisonnement dialectique. Les quaestiones disputatae (questions disput√©es) et les summae (synth√®ses encyclop√©diques) structurent l‚Äôargumentation en √©tapes formelles : question initiale, objections, r√©ponses, r√©solution finale. Chaque √©tape suit des r√®gles pr√©cises d‚Äôinf√©rence, pr√©figurant les algorithmes de d√©cision et les syst√®mes experts modernes ([Thomas d‚ÄôAquin, 1265‚Äì1273](#thomas1265)).

L‚Äôarchitecture cognitive de Thomas d‚ÄôAquin, expos√©e dans sa *Summa Theologica*, combine th√©ologie et logique aristot√©licienne en un syst√®me modulaire : unit√©s conceptuelles (articles) articul√©es selon des r√®gles d‚Äôextraction de conclusions. Cette formalisation du processus intellectuel √©claire l‚Äôid√©e que la pens√©e peut √™tre cod√©e et automatis√©e, principe central des IA symboliques.

**Automates anthropomorphes et m√©canique biomim√©tique**

<div align="center">
   <img src="images/partie2/chevalier.jpg" alt="Chevalier m√©canique de L√©onard de Vinci (1452‚Äì1519)" style="width: 40%; max-width: 600px;">
</div>

*L√©onard de Vinci : anatomie et ing√©nierie*
√Ä la Renaissance, L√©onard de Vinci (1452‚Äì1519) con√ßoit des automates anim√©s par poulies, c√¢bles et ressorts. Son *chevalier m√©canique* (vers 1495) reproduit les mouvements humains ‚Äì lever le bouclier, tourner la t√™te ‚Äì gr√¢ce √† un syst√®me de c√¢bles modulaires et de m√©canismes d‚Äôhorlogerie int√©gr√©s dans une armature anatomique ([de Vinci, s.d](#devinci)).

De Vinci con√ßoit l‚Äôautomate comme outil d‚Äô√©tude du corps, m√™lant biomim√©tisme et programmation mat√©rielle, pr√©figurant les recherches contemporaines en robotique autonome et en robots humano√Ødes.

**Pascaline, Leibniz et l‚Äôautomation arithm√©tique**

Au XVII·µâ si√®cle, Blaise Pascal (1623‚Äì1662) met au point la *Pascaline* (1642), premi√®re machine capable d‚Äôadditionner et soustraire automatiquement via un syst√®me de roues √† dents et sautoirs. Destin√©e √† all√©ger le travail fiscal de son p√®re, elle lib√®re l‚Äôesprit humain des calculs r√©p√©titifs, instaurant l‚Äôid√©e de d√©l√©gation m√©canique des t√¢ches arithm√©tiques ([Pascal, 1642](#pascal1642)).

Gottfried Wilhelm Leibniz (1646‚Äì1716) perfectionne ce concept en cr√©ant la premi√®re machine √† multiplier et diviser m√©caniquement, et formalise le syst√®me binaire (1679) d√©montrant que ‚Äútous les nombres et calculs‚Äù peuvent se r√©duire √† des combinaisons de 0 et 1, fondement de l‚Äôinformatique digitale ([Leibniz, 1679](#leibniz1679)).

**Synth√®se : de la paresse cr√©ative √† l‚Äôautomation syst√©matique**

De l‚Äôhydraulique programmable d‚Äôal-Jazari √† la machine logique de Llull, des horloges-astrarium √† la Pascaline, la p√©riode 800‚Äì1750 incarne la transition d‚Äôune innovation opportuniste √† un projet coh√©rent d‚Äôautomation. Les inventeurs m√©di√©vaux et renaissants traduisent la p√¢resse cr√©ative en programmation m√©canique, jetant les bases de l‚Äôintelligence artificielle contemporaine.

# PARTIE III : Rationalisation m√©canique et calcul (1750-1945)

## 5. Automates sophistiqu√©s, r√©volution industrielle et naissance du calcul m√©canique

> "Entre m√©canique et calcul, les fondements du monde futur se dessinent"
> Des automates Jaquet-Droz aux machines de Babbage, l'industrie naissante de la computation
> 
> Citation inspir√©e de l'Encyclop√©die de Diderot et d'Alembert (1751-1772) sur l'union des arts et des sciences.

**Les Jaquet-Droz : perfection m√©canique et programmation mat√©rielle**

Entre 1768 et 1774, Pierre Jaquet-Droz (1721‚Äì1790) et son fils Henri-Louis (1752‚Äì1791) cr√©ent trois chefs-d'oeuvre de l'automation : l'*√âcrivain*, la *Musicienne* et le *Dessinateur*. Ces automates transcendent la simple imitation pour atteindre une v√©ritable programmation mat√©rielle.

- L'√âcrivain, compos√© de 6000 pi√®ces, constitue la r√©alisation technique la plus sophistiqu√©e de son √©poque. Il peut r√©diger ¬´ n'importe quel texte jusqu'√† quarante lettres ¬ª, en respectant l'espacement, les pleins et d√©li√©s, et m√™me les changements de ligne. Son m√©canisme r√©volutionnaire utilise un syst√®me de cames programmables : en modifiant les disques m√©talliques, on peut changer le texte √† √©crire, instaurant le concept de programmation par support amovible ([Jaquet-Droz, 1775](#jaquet1775)).

- Le Dessinateur (2000 pi√®ces) dessine quatre compositions diff√©rentes ‚Äì portraits de Louis XV et Marie-Antoinette, couple de chiens, cupidon sur char ‚Äì gr√¢ce √† un syst√®me de coordonn√©es m√©caniques anticipant les traceurs automatiques modernes. Henri-Louis enrichit le r√©pertoire en programmant de nouveaux dessins, d√©montrant la modularit√© du syst√®me.

- La Musicienne (2500 pi√®ces) joue r√©ellement du clavecin, ses doigts appuyant sur les touches avec la pression appropri√©e, sa poitrine se soulevant comme si elle respirait. Ces automates r√©v√®lent une synth√®se in√©dite entre art, m√©canique et programmation, pr√©figurant les interfaces homme-machine contemporaines.

**Babbage et Lovelace : l'ordinateur avant la lettre**

En 1834, Charles Babbage (1791‚Äì1871) con√ßoit la *Machine analytique*, premi√®re conception compl√®te d'un ordinateur universel. Contrairement √† ses machines √† diff√©rences, purement arithm√©tiques, cette machine peut ¬´ effectuer n'importe quelle op√©ration via un jeu d'instructions bas√© sur des cartes perfor√©es ¬ª inspir√©es du m√©tier *Jacquard* ([Babbage, 1834](#babbage1834)).

La Machine analytique distingue clairement donn√©es et programme, poss√®de une m√©moire (¬´ store ¬ª) et une unit√© de calcul (¬´ mill ¬ª), et peut ex√©cuter des boucles conditionnelles. Cette architecture anticipe de plus d'un si√®cle les principes de *von Neumann*.

Ada Lovelace (1815‚Äì1852) per√ßoit le potentiel r√©volutionnaire de cette machine. Dans ses Notes (1843), elle d√©veloppe le premier algorithme informatique pour calculer les nombres de Bernoulli, incluant la premi√®re boucle conditionnelle de l'histoire ([Lovelace, 1843](#lovelace1843)). Plus visionnaire encore, elle √©nonce que ¬´ la machine pourrait composer de mani√®re scientifique et √©labor√©e des morceaux de musique de n'importe quelle longueur ou degr√© de complexit√© ¬ª, anticipant l'IA cr√©ative contemporaine.

**Boole : l'alg√®bre de la logique**

George Boole (1815‚Äì1864) r√©volutionne la logique en cr√©ant une alg√®bre binaire n'acceptant que deux valeurs : 0 et 1. Dans *An Investigation of the Laws of Thought* (1854), il d√©montre que ¬´ des id√©es et des concepts ¬ª peuvent √™tre traduits ¬´ en √©quations ¬ª, puis retrait√©s ¬´ en termes logiques ¬ª ([Boole, 1854](#boole1854)).

L'alg√®bre bool√©enne introduit les op√©rations ET, OU et NON, avec leurs propri√©t√©s de commutativit√©, distributivit√© et idempotence. Cette formalisation constitue les fondements math√©matiques de l'informatique et des circuits √©lectroniques. Boole r√©alise le r√™ve de Leibniz : transformer tout raisonnement en ¬´ calcul automatique ¬ª.

**Hollerith : industrialisation du traitement de l'information**

En 1890, Herman Hollerith (1860‚Äì1929) r√©volutionne le traitement statistique avec ses machines √† cartes perfor√©es pour le recensement am√©ricain. Son syst√®me r√©duit le d√©pouillement ¬´ d'un travail de dix ans √† trois mois ¬ª et √©conomise cinq millions de dollars ([Hollerith, 1890](#hollerith1890)).

La *tabulatrice Hollerith* combine lecture √©lectrom√©canique et compilation automatique : les cartes perfor√©es passent sur un r√©seau de picots m√©talliques qui ferment des circuits √©lectriques au contact du mercure, actionnant des compteurs √©lectromagn√©tiques. Ce syst√®me pr√©figure l'architecture informatique : support de donn√©es (cartes), lecteur (picots), processeur (circuits √©lectriques) et sortie (compteurs).

En 1896, Hollerith fonde la *Computing-Tabulating-Recording Company* qui deviendra IBM (International Business Machines Corporation) en 1924. Ses machines √©quipent les recensements de nombreux pays, inaugurant l'industrie du traitement automatis√© de l'information.

## 6. Tensions fondatrices : crises, alg√®bre, incompl√©tude et formalisations modernes

> ‚ÄúLes math√©matiques peuvent tout montrer, sauf leur propre fondement.‚Äù
> 
> Citation inspir√©e des th√©or√®mes d‚Äôincompl√©tude de Kurt G√∂del (1931).

**Russell et Whitehead : l'ambition logiciste**

Au d√©but du XX·µâ si√®cle, Bertrand Russell (1872‚Äì1970) et Alfred North Whitehead (1861‚Äì1947) entreprennent de r√©duire l'ensemble des math√©matiques √† la logique pure dans leurs monumentaux *Principia Mathematica* (1910‚Äì1913) ([Whitehead & Russell, 1910‚Äì1913](#whitehead1910)).

Cette ≈ìuvre de 2000 pages formalise la logique moderne : calcul des propositions, des pr√©dicats et des relations. Elle introduit la th√©orie des types logiques pour r√©soudre les paradoxes, notamment celui de Russell : ¬´ un ensemble ne peut appartenir √† lui-m√™me ¬ª. Les Principia √©tablissent les fondements formels de l'informatique th√©orique et de l'IA symbolique.

**ƒåapek et le mot "robot"**

En 1920, l'√©crivain tch√®que Karel ƒåapek (1890‚Äì1938) introduit le mot "robot" (du tch√®que robota : travail forc√©) dans sa pi√®ce R.U.R. (Rossum's Universal Robots). Ces cr√©atures artificielles, initialement dociles, se r√©voltent contre leurs cr√©ateurs, inaugurant la mythologie moderne de l'intelligence artificielle et questionnant la relation homme-machine ([ƒåapek, 1920](#capek1920)).

**G√∂del : l'effondrement du r√™ve formaliste**

En 1931, Kurt G√∂del (1906‚Äì1978) ruine d√©finitivement le programme formaliste d'Hilbert avec ses th√©or√®mes d'incompl√©tude. Le premier √©nonce que dans ¬´ n'importe quelle th√©orie r√©cursivement axiomatisable, coh√©rente et capable de formaliser l'arithm√©tique, on peut construire un √©nonc√© arithm√©tique qui ne peut √™tre ni d√©montr√© ni r√©fut√© ¬ª ([G√∂del, 1931](#godel1931))(G√∂del, 1931).

Le second th√©or√®me √©tablit qu'¬´ une th√©orie coh√©rente ne peut d√©montrer sa propre coh√©rence ¬ª. Ces r√©sultats r√©v√®lent les limites intrins√®ques de la formalisation : il existera toujours des √©nonc√©s vrais mais ind√©montrables. Cette d√©couverte fondamentale influencera d√©cisivement le d√©veloppement de l'informatique th√©orique et de l'IA, notamment les travaux de Turing sur la calculabilit√©.

**Synth√®se : m√©canisation et limites de la raison**

La p√©riode 1750‚Äì1945 transforme la paresse cr√©ative en industrie de l'automation. Des automates Jaquet-Droz aux machines Hollerith, en passant par les conceptions de Babbage et les formalisations de Boole, √©merge une technologie syst√©matique du calcul et de la logique.

Paradoxalement, cette √©poque d'optimisation m√©canique r√©v√®le aussi les limites fondamentales de la formalisation avec G√∂del. Cette tension entre ambitions computationnelles et impossibilit√©s logiques structure les d√©veloppements futurs de l'informatique et de l'intelligence artificielle, pr√©parant les r√©volutions th√©oriques du XX·µâ si√®cle.

# PARTIE IV : L'√¢ge d'or th√©orique & av√®nement des machines (1945-1970)

> ‚ÄúTout calcul qui peut √™tre fait par un esprit humain peut aussi √™tre effectu√© par une machine universelle.‚Äù
> 
> Inspir√© d‚ÄôAlan Turing, On Computable Numbers (1936).

## 7. Math√©maticiens et ing√©nieurs de la computation

Alan Turing √©tablit en 1936 que toute fonction calculable peut √™tre effectu√©e par une machine de Turing universelle : un automate abstrait lisant et √©crivant des symboles sur une bande infinie selon un ensemble d‚Äô√©tats finis. Cette structure d√©montre la computeabilit√© des op√©rations math√©matiques et fixe les limites intrins√®ques de ce qui peut √™tre programm√©. En 1950, Turing propose le Test de Turing comme crit√®re d‚Äôintelligence artificielle : si une machine parvient √† imiter la conversation humaine sans √™tre distingu√©e d‚Äôun interlocuteur humain, elle peut √™tre consid√©r√©e comme ¬´ pensante ¬ª ([Turing, 1936](#turing1936)).

En 1943, Warren McCulloch et Walter Pitts mod√©lisent le neurone biologique par une unit√© binaire activ√©e par un seuil dans *A Logical Calculus of the Ideas Immanent in Nervous Activity*. Leur neurone formel devient la pierre angulaire du **connexionnisme**, inspirant plus tard les r√©seaux de neurones artificiels ([McCulloch & Pitts, 1943](#mcculloch1936)).

Claude Shannon, souvent appel√© le p√®re de la th√©orie de l‚Äôinformation, publie en 1948 *A Mathematical Theory of Communication*, posant les bases du codage de l‚Äôinformation, de la compression et de la transmission fiable. Ses concepts de bit et d'entropie influencent profond√©ment l‚Äôarchitecture des ordinateurs et le traitement du signal dans les syst√®mes intelligents ([Shannon, 1948](#shannon1948)).

John von Neumann formalise d√®s 1945 dans le *First Draft of a Report on the EDVAC* une architecture s√©quentielle stock√©e, distinguant m√©moire, unit√© arithm√©tique, unit√© de contr√¥le et interfaces d‚ÄôEntr√©e/Sortie. Ce mod√®le, connu sous le nom d‚Äôarchitecture von Neumann, demeure la r√©f√©rence des ordinateurs jusqu‚Äôau XXI·µâ si√®cle ([von Neumann, 1945](#von1945)).

En 1948, Norbert Wiener publie *Cybernetics: Or Control and Communication in the Animal and the Machine*, √©tablissant l'**approche cybern√©tique**. Il d√©montre l‚Äôimportance de la r√©troaction et de l‚Äôautor√©gulation dans les syst√®mes vivants et m√©caniques, th√©orie essentielle pour la conception de robots adaptatifs et de syst√®mes de pilotage automatique ([Wiener, 1948](#wiener1948)).

## 8. Naissance officielle de l‚ÄôIA : crit√®res, conf√©rence et premiers programmes

Le concept d‚ÄôIA se cristallise en 1950 lorsque Turing obtient un score probant au Test de Turing, soulevant des d√©bats philosophiques majeurs sur la conscience des machines et la nature de l‚Äôintelligence ([Turing, 1950](#turing1950)).

En 1956, la conf√©rence de Dartmouth, initi√©e par John McCarthy, Marvin Minsky, Nathan Rochester et Claude Shannon, formalise l‚ÄôIA comme un domaine distinct. Le projet vise √† cr√©er des machines simulant tous aspects de l‚Äôintelligence humaine : pens√©e, apprentissage, raisonnement logique et vision ([McCarthy et al., 1956](#mccarthy1956)).

Cette m√™me d√©cennie voit na√Ætre les premiers syst√®mes :

- *Spatial Numerical Association of Response Code* (SNARC) (1951) de Marvin Minsky et Dean Edmonds est le premier simulateur de r√©seau de neurones mat√©riel, reliant cylindres rotatifs pour imiter la dynamique de petits r√©seaux neuronaux ([Minsky & Edmonds, 1951](#minsky1951)).

- *Logic Theorist* (1956) d‚ÄôAllen Newell et Herbert A. Simon simule la d√©monstration de th√©or√®mes logiques en utilisant des heuristiques pour guider la recherche dans l‚Äôespace des preuves, inaugurant les syst√®mes experts symboliques ([Newell & Simon, 1956](#newell1956)).

- *Perceptron* (1958) de Frank Rosenblatt impl√©mente un r√©seau simple capable d‚Äôapprendre par ajustement it√©ratif de poids, ouvrant la voie √† l‚Äôapprentissage automatique ([Rosenblatt, 1958](#rosenblatt1958)).

- *Logic Theorist, General Problem Solver* et les premiers programmes de traitement du langage naturel illustrent l‚Äôoptimisme de l‚Äô√®re, avant que les limitations computationnelles et la crise des hivers de l‚ÄôIA n‚Äôapparaissent.

# PARTIE V : Cycles d'enthousiasme, hivers et paradigmes √©mergents (1970-2000)

## 9. Approches symboliques et connexionnistes : premiers antagonismes

> *"L‚Äôoptimisme algorithmique a d‚Äôabord connu son √©clat avant de rencontrer ses propres limites."*
> 
> Inspir√© du constat de Geoffrey Hinton sur l‚ÄôIA (2012).

Dans les ann√©es 1970, l‚ÄôIA se divise entre deux visions concurrentes. L‚Äô**IA symbolique** repose sur la manipulation explicite de symboles et de r√®gles logiques, incarn√©e par les syst√®mes experts utilisant des langages de programmation d√©claratifs et des bases de connaissances. √Ä l‚Äôinverse, l‚Äô**IA connexionniste** s‚Äôinspire du fonctionnement neuronal, avec des r√©seaux de neurones artificiels capables d‚Äôapprendre par l‚Äôajustement de poids ([McCulloch & Pitts, 1943](#mcculloch1943) ; [Rosenblatt, 1958](#rosenblatt1958)).

Cette dualit√© alimente un optimisme f√©roce : les symbolistes promettent la compr√©hension gr√¢ce √† la logique formelle, tandis que les connexionnistes misent sur la capacit√© d‚Äôapprentissage face √† la variabilit√© du monde r√©el. Chacune des approches exhibe des succ√®s initiaux mais montre rapidement ses limites sp√©cifiques : rigidit√© des r√®gles symboliques vs. opacit√© et instabilit√© des r√©seaux neuronaux.

## 10. Premier hiver de l‚ÄôIA : r√©alit√©s et d√©sillusions (1974‚Äì1980)

> *‚ÄúLes hivers de l‚ÄôIA r√©v√®lent la difficult√© de transformer les promesses en performances concr√®tes.‚Äù*
> 
> Citation inspir√©e du rapport Lighthill (1973).

Le rapport Lighthill remis au gouvernement britannique en 1973 critique s√©v√®rement les progr√®s de l‚ÄôIA symbolique, soulignant l‚Äô√©chec √† g√©rer la complexit√© du monde r√©el et pr√©conisant la r√©duction des financements dans ce secteur ([Lighthill, 1973](#lighthill1973)). Cette crise de confiance inaugure le premier hiver de l‚ÄôIA, marqu√© par des coupes budg√©taires massives, l‚Äôabandon de projets ambitieux et une d√©sillusion g√©n√©rale chez les chercheurs et les financeurs.

L‚Äôeffondrement est accentu√© par les travaux de Minsky et Papert (1969) qui d√©montrent les limites structurelles des perceptrons, incapables de r√©soudre des probl√®mes non lin√©aires simples comme le XOR (fonction OU) ([Minsky & Papert, 1969](#minsky1969)). Leur critique technique entra√Æne un recul durable de la recherche connexionniste.

## 11. Renaissance des syst√®mes experts et Mardi noir de l‚ÄôIA (1980‚Äì1987)

> *‚ÄúLa connaissance, stock√©e sous formes de r√®gles, devint soudainement pr√©cieuse.‚Äù*
> 
> Inspir√© de l‚Äôessor de *MYCIN* (1975).

Au d√©but des ann√©es 1980, l‚Äô√©mergence des syst√®mes experts offre un renouveau symbolique. *MYCIN* ([Shortliffe, 1976](#shortliffe1976)) pour le diagnostic m√©dical et *DENDRAL* (1965) en chimie d√©montrent la puissance des bases de connaissances codifi√©es par des experts humains. L‚Äôentreprise DEC commercialise *XCON/R1* pour la configuration de serveurs, g√©n√©rant des √©conomies substantielles pour *Digital Equipment Corporation* ([McDermott, 1982](#mcdermott1982)).

Cet √¢ge d‚Äôor commercial culmine en 1987, lorsque l‚Äôaction des entreprises d‚ÄôIA atteint son apog√©e, avant de chuter brutalement lors du "Mardi noir de l‚ÄôIA", marqu√© par l‚Äôeffondrement du cours des actions des soci√©t√©s sp√©cialis√©es, victimes de performances d√©cevantes et de la complexit√© des syst√®mes sur le terrain ([Crevier, 1993](#crevier1993)).

## 12. Deuxi√®me hiver et transition statistique (1987‚Äì1997)

> *‚ÄúQuand le symbole √©choue, la statistique √©merge.‚Äù*
> 
> Citation inspir√©e de Judea Pearl (1988).

√Ä la fin des ann√©es 1980, la r√©alit√© commerciale rattrape les promesses symboliques : les co√ªts de d√©veloppement croissants et la difficult√© d‚Äôextension des r√®gles entra√Ænent un d√©senchantement. Ce deuxi√®me hiver est att√©nu√© par la r√©volution statistique : l‚Äôessor des r√©seaux bay√©siens, popularis√©s par Judea Pearl ([Pearl, 1988](#pearl1988)), et la renaissance des r√©seaux de neurones gr√¢ce aux algorithmes de r√©tropropagation red√©couverts par Rumelhart et Hinton ([Rumelhart & Hinton, 1986](#rumelhart1986)).

La victoire de *Deep Blue* sur Garry Kasparov (1997) marque un tournant : l‚ÄôIA symbolique c√®de la place √† une IA hybride, combinant approches statistiques, connexionnistes et symboliques, annon√ßant l‚Äôapprentissage automatique et pr√©parant l‚Äô√®re Internet.

# PARTIE VI : Convergence et synth√®se contemporaine (2000-2025)

> *"Les donn√©es sont le carburant, le deep learning en est le moteur."*
> 
> Inspir√© de Geoffrey Hinton, discours sur le deep learning (2012).

## 11. L‚Äô√®re Internet et renaissance du machine learning

√Ä partir des ann√©es 2000, l‚Äôexplosion des donn√©es num√©riques issue d‚ÄôInternet et des r√©seaux sociaux permet l‚Äôessor du machine learning. Les entreprises exploitent des flots massifs de donn√©es pour entra√Æner des mod√®les statistiques, marquant la transition du *connexionnisme* pur vers des approches *data-driven* ([Jordan & Mitchell, 2015](#jordan2015)). Le *PageRank* de Google ([Brin & Page, 1998](#brin1998)) illustre ce paradigme : un algorithme probabiliste classant les pages web en s‚Äôappuyant sur la structure du graphe, annon√ßant la r√©volution de la recommandation et de la recherche personnalis√©e.

## 12. R√©volution deep learning et √©mergence neuro-symbolique

> *‚ÄúLa profondeur des r√©seaux r√©v√®le la richesse des donn√©es.‚Äù*
> 
> Inspir√© de Yoshua Bengio, entretien sur le deep learning (2018).

En 2012, AlexNet de Krizhevsky, Sutskever et Hinton remporte le concours *ImageNet* en r√©duisant drastiquement le taux d‚Äôerreur en vision par ordinateur gr√¢ce √† un *r√©seau de neurones convolutifs (CNN) profonds*  ([Krizhevsky et al., 2012](#krizhevsky2012)). Cet exploit relance l‚Äôint√©r√™t pour les CNN et inspire la prolif√©ration de mod√®les tels que *VGG, ResNet et GANs,* ces derniers con√ßus par Goodfellow et al. pour g√©n√©rer des images r√©alistes via deux r√©seaux en comp√©tition ([Goodfellow et al., 2014](#goodfellow2014)).

Parall√®lement, l‚ÄôIA neuro-symbolique refait surface, combinant apprentissage profond et raisonnement symbolique. Des frameworks comme *Neuro-Symbolic Concept Learner* ([Mao et al., 2019](#mao2019)) d√©montrent comment int√©grer la structure logique dans les r√©seaux neuronaux pour am√©liorer la compr√©hension du langage et la vision.

## 13. √àre Transformers et explosion g√©n√©rative

> *‚ÄúL‚Äôattention est la nouvelle m√©moire.‚Äù*
> 
> Inspir√© de Vaswani et al., Attention Is All You Need (2017).

En 2017, Vaswani et al. r√©volutionnent le *traitement du langage naturel* (NLP) avec l‚Äôarchitecture *Transformer*, bas√©e uniquement sur m√©canismes d‚Äôattention, √©liminant la r√©cursion et acc√©l√©rant l‚Äôentra√Ænement ([Vaswani et al., 2017](#vaswani2017)). Cette innovation donne naissance √† *BERT* ([Devlin et al., 2018](#devlin2018)) pour la compr√©hension de textes et √† *GPT* ([Radford et al., 2018](#radford2018)), dont *GPT-3* ([Brown et al., 2020](#brown2020)) g√©n√®re du texte coh√©rent sur de vastes contextes.

La g√©n√©ration multimodale s‚Äô√©tend aux images et au code : *DALL¬∑E* ([Ramesh et al., 2021](#ramesh2021)) cr√©e des images √† partir de descriptions textuelles, et *Codex* ([Chen et al., 2021](#chen2021)) produit du code fonctionnel. Ces avanc√©es d√©mocratisent l‚ÄôIA g√©n√©rative grand public, tout en soulevant des questions sur les droits d‚Äôauteur et la d√©sinformation.

## 14. Course concurrentielle et pi√®ge de Moloch

> *‚ÄúLa comp√©tition acc√©l√®re, mais la coordination stagne.‚Äù*
> 
> Citation inspir√©e d‚ÄôOwen Cotton-Barratt sur le pacte-molochien (2020).

Depuis 2020, la course aux mod√®les de grande √©chelle oppose entreprises et √âtats, √† tel point que des architectures comme *GPT-4* et *PaLM* rivalisent de capacit√©s multimodales ([OpenAI, 2023](#openai2023)). Cette concurrence sans coordination s‚Äôapparente √† un pi√®ge de Moloch, o√π l‚Äôacc√©l√©ration de la puissance sacrifi√©e au d√©triment de la s√©curit√© et de l‚Äô√©thique engendre des risques syst√©miques ([Yudkowsky, 2020](#yudkowsky2020)).

Dans ce contexte, √©mergent des initiatives de gouvernance : *OpenAI Charter* (2018) et *Partenariat sur l‚ÄôIA* (2016) visent √† instaurer des normes pour une IA s√©curis√©e et b√©n√©fique. Pourtant, le d√©fi reste d‚Äôaligner les int√©r√™ts de multiples acteurs mondiaux pour √©viter une spirale comp√©titive aux cons√©quences impr√©visibles.

# PARTIE VII : Vers une nouvelle intelligence - La r√©volution Fristonienne

## 15. Karl Friston et le principe de l‚Äô√©nergie libre

> L‚Äôesprit pr√©dit, la machine op√®re : l‚Äôinf√©rence active r√©v√®le la prochaine fronti√®re."
> 
> Inspir√© de Karl Friston, conf√©rence sur le Free Energy Principle (2010).

Karl Friston propose dans les ann√©es 2000 le *Free Energy Principle* (FEP), un cadre unifiant la neurosciences et l‚Äôintelligence artificielle. Le FEP postule que les organismes vivants minimisent en permanence une fonction d‚Äô√©nergie libre, mesurant la divergence entre leurs mod√®les internes (pr√©dictions) et les donn√©es sensorielles r√©elles. Cette minimisation de la surprise (surprisal) guide la perception, l‚Äôaction et l‚Äôapprentissage ([Friston, 2010](#friston2010)).

Friston formalise l‚Äô*active inference* : un agent n‚Äôa pas seulement √† mettre √† jour ses croyances (perception) pour r√©duire l‚Äô√©nergie libre, mais aussi √† agir pour s√©lectionner des observations qui v√©rifient ses pr√©dictions. Cette boucle perception-action rapproche l‚ÄôIA des syst√®mes biologiques, offrant un mod√®le bio-inspir√© pour la conception de robots adaptatifs ([Friston et al., 2016](#friston2016)).

Des impl√©mentations r√©centes, comme le *Variational Ensemble of Reservoir-based Embodied Systems* (VERSES AI), d√©montrent l‚Äôapplication concr√®te de l‚Äôactive inference √† des robots mobiles capables de naviguer dans des environnements dynamiques en pr√©diction continue et en r√©ajustement autonome ([Millidge et al., 2020](#millidge2020)).

## 16. Facteurs humains et IA centr√©e sur l‚Äôhumain

> *‚ÄúUne interface bien con√ßue anticipe et r√©duit l‚Äôeffort mental, elle n‚Äôen ajoute pas.‚Äù*
> 
> Inspir√© de Wickens, Engineering Psychology and Human Performance (2008).

### 16.1 Ergonomie cognitive et interfaces adaptatives
Sortant d‚Äôun master STAPS (Sciences et Techniques des Activit√©s Physiques et Sportives) orient√© facteurs humains, il est crucial de replacer l‚Äôhumain au c≈ìur de la r√©volution IA. L‚Äôergonomie cognitive √©tudie comment concevoir des interfaces homme-machine qui minimisent la charge cognitive, optimisent la facilit√© d‚Äôapprentissage et favorisent la s√©curit√© ([Wickens, 2008](#wickens2008)).

Les syst√®mes adaptatifs bas√©s sur l‚Äôactive inference ajustent en temps r√©el les demandes cognitives en fonction de l‚Äô√©tat mental de l‚Äôutilisateur, mesur√© par des capteurs biom√©triques (fr√©quence cardiaque, mouvements oculaires). Cette approche permet de pr√©venir la surcharge et d‚Äôoptimiser les performances motrices dans le sport, la m√©decine et l‚Äôaviation ([Hoffman & Hancock, 2018](#hoffman2018)).

### 16.2 Lecture des pens√©es par mouvements oculaires
Le mod√®le de Yarbus (1967) a d√©montr√© que les mouvements oculaires (saccades) refl√®tent les intentions cognitives lors de la lecture et de l‚Äôexploration visuelle ([Yarbus, 1967](#yarbus1967)). En inversant ce mod√®le, on peut d√©duire les intentions d‚Äôun individu √† partir de ses trajectoires oculaires : c‚Äôest la base d‚Äôune IA oculaire capable de lire les pens√©es implicites ([Paletta et al., 2013](#paletta2013)).

Des prototypes exp√©rimentaux utilisent des syst√®mes d'*eye-tracking* coupl√©s √† des r√©seaux neuronaux profonds pour pr√©dire les objectifs d‚Äôun utilisateur en temps r√©el, ouvrant des perspectives en ergonomie, r√©√©ducation et s√©curit√© industrielle ([Vidal & Piater, 2018](#vidal2018)).

### 16.3 Cognition √©nactive et syst√®mes bio-inspir√©s
L‚Äô√©nactivisme postule que la cognition √©merge de l‚Äôinteraction dynamique entre l‚Äôagent et son environnement. Int√©gr√©e au FEP, cette perspective cr√©e des robots non seulement pr√©dictifs, mais aussi incarn√©s, tirant avantage de leur morphologie et de leur biomechanique pour accomplir des t√¢ches complexes ([O‚ÄôRegan & No√´, 2001](#oregan2001)).

Ces syst√®mes bio-inspir√©s combinent l‚Äôinf√©rence active, la programmation hydraulique antique et l‚Äôapprentissage profond, illustrant la convergence des paradigmes IA vers une intelligence v√©ritablement int√©gr√©e.

# PARTIE VIII : Le√ßons des √©checs et succ√®s technologiques

> *"L‚Äô√©chec r√©v√®le les fragilit√©s, le succ√®s d√©pend de l‚Äôad√©quation entre technologie, march√© et contexte humain."*
> 
> Citation inspir√©e de Clayton Christensen, The Innovator‚Äôs Dilemma (1997).

Les innovations en intelligence artificielle connaissent autant d‚Äô√©checs retentissants que de succ√®s durables. Analyser les causes profondes de ces performances divergentes √©claire les facteurs cl√©s de la r√©ussite : maturit√© technologique, alignement avec les besoins utilisateurs, mod√®le √©conomique et acceptabilit√© sociale.

## 17. √âchecs embl√©matiques et analyses critiques

Les *Google Glass* (2013‚Äì2015) illustrent l‚Äô√©chec d‚Äôune technologie avanc√©e mais pr√©matur√©e. Malgr√© des capacit√©s de r√©alit√© augment√©e in√©dites, elles souffraient d‚Äôun √©cosyst√®me applicatif immature, d‚Äôun prix prohibitif (1500 $) et d‚Äôenjeux de vie priv√©e non ma√Ætris√©s. Le lancement public trop rapide a r√©v√©l√© l‚Äôabsence de cas d‚Äôusage concrets, tandis que le design suscitait rejet et hostilit√© sociale, fragilisant l‚Äôadoption ([Google Inc., 2015)](#google2015)).

Les voitures autonomes de niveau 5 peinent √† se d√©ployer √† grande √©chelle en raison de la complexit√© du monde r√©el. Les capteurs (lidar, radar, cam√©ras) offrent une vision partielle, difficile √† fusionner en temps r√©el pour g√©rer les situations impr√©vues (chantier de travaux, comportement humain complexe). La r√©glementation varie selon les juridictions et la responsabilit√© en cas d‚Äôaccident reste floue, freinant les investissements et la confiance du public ([Bymycar Webzine, 2025](#bymycar2025) ; [SAE International, 2018)](#sae2018) ; [Le Monde, 2025)](#lemonde2025)) 

IBM Watson for Oncology (2013‚Äì2020) promettait une r√©volution m√©dicale. Pourtant, Watson repose sur des donn√©es propri√©taires et homog√®nes provenant de grandes institutions, ce qui g√©n√®re des biais et r√©duit sa g√©n√©ralisabilit√© aux h√¥pitaux du monde r√©el. Les cliniciens rapportent une concordance de 33% avec les protocoles existants et un manque de transparence sur les recommandations, limitant la confiance et l‚Äôadoption ([Stat News., 2017](#stat2017) ; [Caducee.net., 2016](#caducee2016))

## 18. Succ√®s instructifs et bonnes pratiques

Le syst√®me de recommandation de *Netflix*, mis en place d√®s 2006, constitue un succ√®s durable. En exploitant de grandes volum√©tries de donn√©es historiques et en combinant filtrage collaboratif et mod√®les de machine learning, *Netflix* a su offrir des suggestions personnalis√©es qui am√©liorent l‚Äôengagement utilisateur et r√©duisent le churn (taux d‚Äôabandon). Une exp√©rience syst√©matique d‚ÄôA/B testing et l‚Äôint√©gration continue des retours utilisateurs ont permis de faire √©voluer l‚Äôalgorithme sans rupture, garantissant la pertinence des recommandations et une forte fid√©lisation ([Gomez-Uribe & Hunt, 2015](#gomez2015)).

Le robot aspirateur *Roomba d‚ÄôiRobot* (depuis 2002) est un autre exemple de r√©ussite. Gr√¢ce √† une expertise en robotique embarqu√©e, des capteurs infrarouges et des algorithmes de navigation al√©atoire simplifi√©s, *Roomba* a propos√© un cas d‚Äôusage concret (nettoyage automatique √† domicile) parfaitement adapt√© aux besoins des consommateurs. La simplicit√© d‚Äôutilisation, l‚Äôabsence de barri√®re r√©glementaire et le prix abordable ont favoris√© une adoption massive, transformant un gadget en march√© grand public prosp√®re ([iRobot, 2005](#irobot2005)).

## 19. Enjeux cl√©s et perspectives
Ces √©tudes de cas convergent vers quatre facteurs structurants pour la r√©ussite des projets d‚ÄôIA :

1. Maturit√© technologique : les algorithmes doivent √™tre robustes et cr√©dibles avant la mise sur le march√©.

2. Alignement utilisateur : l‚Äôinnovation doit r√©pondre √† des besoins concrets et s‚Äôint√©grer harmonieusement dans les parcours existants.

3. √âcosyst√®me et donn√©es : la qualit√©, la diversit√© et la disponibilit√© des donn√©es sont d√©terminantes; un √©cosyst√®me logiciel (API, plateformes) facilite l‚Äôadoption.

4. Acceptabilit√© sociale et r√©gulation : la confiance passe par la transparence, l‚Äôexplicabilit√© et un cadre r√©glementaire clair.

En appliquant ces enseignements, les futurs projets d‚ÄôIA ‚Äì qu‚Äôils soient bas√©s sur le *Free Energy Principle*, la vision oculaire ou la robotique oc√©anique ‚Äì pourront maximiser leurs chances de succ√®s, en √©vitant les √©cueils qui ont entrav√© les pionniers.

# PARTIE IX : Futurs possibles et imaginaires critiques

> *"La fronti√®re entre l‚Äôhumain et la machine n‚Äôest pas une barri√®re, mais une passerelle."*
> 
> Citation inspir√©e de Norbert Wiener, Cybernetics (1948).

## 20. Vers l‚ÄôAGI bio-inspir√©e : Active Inference et conscience artificielle

Alan Turing a montr√© que toute op√©ration calculable est r√©alisable par une machine abstraite, mais l‚ÄôArtificial General Intelligence (AGI) exige une ma√Ætrise de l‚Äôautonomie adaptative et de la conscience artificielle. Le Free Energy Principle de Friston unifie perception, action et apprentissage sous la minimisation de l‚Äô√©nergie libre, offrant un cadre pour des agents bio-inspir√©s capables de pr√©dire et de s√©lectionner leurs observations pour r√©duire la surprise interne. De telles AGI combineraient r√©seaux de neurones profonds pour l‚Äôextraction multi-modale, m√©canismes d‚Äôattention pour focaliser les ressources computationnelles et boucles d‚Äôactive inference pour assurer une autonomie adaptative dans des environnements inconnus.

## 21. Black Mirror et prospective critique : dystopies et coop√©rations

Les √©pisodes de *Black Mirror* dessinent des sc√©narios extr√™mes ‚Äì notation sociale omnipr√©sente, implants de surveillance parentale ‚Äì qui questionnent la vie priv√©e, la libert√© psychique et les pouvoirs algorithmiques. Ils rappellent l‚Äôenjeu d‚Äôune gouvernance proactive, visant √† encadrer la surveillance intrusive, promouvoir l‚Äôinterop√©rabilit√© des normes internationales et d√©velopper une litt√©ratie num√©rique critique pour √©duquer les citoyens aux implications √©thiques de l‚ÄôIA.

## 22. L‚Äôodyss√©e inachev√©e : vers une intelligence augment√©e et collaborative

L‚ÄôIA de demain se con√ßoit en symbiose avec l‚Äôhumain. Plut√¥t que de chercher √† surpasser l‚Äôhomo sapiens, il s‚Äôagit de d√©velopper une intelligence augment√©e (IA+H) : co-pilotage cognitif pour la recherche, la cr√©ation et la prise de d√©cision. Les √©cosyst√®mes humains-IA seront des plateformes interactives o√π experts et agents intelligents collaborent en boucles de r√©troaction continue, maximisant l‚Äôefficacit√© tout en pr√©servant l‚Äôautonomie humaine. Cette co√©volution requiert l‚Äôalignement des architectures algorithmiques sur les besoins, les valeurs et la dignit√© de chaque individu.

# PARTIE X : √âvolution de l‚Äô√©thique de l‚ÄôIA

> *"La technologie ne conna√Æt ni bien ni mal ; c‚Äôest son usage qui construit l‚Äô√©thique."*
> 
> Citation inspir√©e de Luciano Floridi, The Ethics of Information (2013).

## 23. √âvolution de l‚Äô√©thique de l‚ÄôIA

L‚Äô√©thique de l‚ÄôIA s‚Äôest structur√©e en trois temps :

1. Principes et chartes : *Asilomar 1975* initie une √©thique anticipative, la *D√©claration de Montr√©al* (2018) pose dix principes dont la ¬´ primaut√© du bien-√™tre humain ¬ª et ¬´ le respect de la vie priv√©e ¬ª, l‚Äô*OpenAI Charter* (2018) engage √† diffuser largement les b√©n√©fices et √† √©viter la course aux armements algorithmiques.

2. R√©gulations : le *R√®glement G√©n√©ral sur la Protection des Donn√©es* (RGPD) (2018) conf√®re droits d‚Äôacc√®s, portabilit√© et effacement sur les donn√©es personnelles, l‚ÄôAI Act (2021) classe les risques et impose la transparence pour les syst√®mes √† risque √©lev√©, le *NIST AI RMF* (2023) propose un cadre volontaire de gestion des risques.

3. Gouvernance mondiale : les *Principes OCDE* (2019) recommandent divulgation, robustesse et respect des droits humains, l‚Äô*UNESCO* (2021) adopte une recommandation engageant 193 √âtats √† promouvoir justice algorithmique, inclusion et durabilit√©.

Les d√©fis √©mergents incluent : responsabilit√© juridique des IA, explicabilit√© des d√©cisions, lutte contre les biais et √©quit√© pour les populations vuln√©rables, adoption de techniques de privacy-preserving machine learning comme la differential privacy.

# Conclusion

Cet *‚ÄúOdyss√©e de l‚ÄôIA‚Äù* r√©v√®le une continuit√© anthropologique : la *¬´ paresse cr√©ative ¬ª* a toujours pouss√© l‚Äôhumanit√© √† externaliser ses efforts physiques et cognitifs, des premiers outils en pierre aux algorithmes profonds. Chaque √©chec, des *Google Glass* aux voitures autonomes, nous enseigne la valeur du timing, de l‚Äô√©cosyst√®me et de la confiance sociale. Chaque succ√®s, de *Netflix* √† *Roomba*, illustre la puissance d‚Äôun alignement pr√©cis entre besoins r√©els et maturit√© technologique.

Le futur de l‚ÄôIA ne se jouera pas sur une confrontation Homme-machine, mais sur une co-cr√©ation o√π l‚ÄôIA amplifie nos capacit√©s cr√©atives, pr√©voit nos intentions et soutient nos d√©cisions critiques. L‚Äôintelligence augment√©e se d√©ploie comme un pont entre notre imagination mill√©naire et les possibles in√©dits d‚Äôune √®re num√©rique responsable et √©thique.

En embrassant l‚Äôinf√©rence active, la neuro-symbolique et l‚Äôergonomie cognitive, nous pourrons concevoir des syst√®mes o√π l‚Äôhumain reste le chef d‚Äôorchestre, guidant la partition algorithmique vers une harmonie collective, bien au-del√† du simple calcul.

# üìö 8. Bibliographie

<a name="aljazari1206"></a>
- al‚ÄëJazarƒ´, A. (1206). KitƒÅb fƒ´ ma ørifat al-·∏•iyal al-handasiyya [Livre sur la connaissance des machines ing√©nieuses]
<a name="apollonius"></a>
- Apollonius de Rhodes. (s.d.). Argonautiques (IV, 1638‚Äë1648)
<a name="aristote"></a>
- Aristote. (s.d.). Premiers Analytiques (I, 4).
<a name="babbage1834"></a>
- Babbage, C. (1834). On the principles of the analytical engine [Machine analytique]
<a name="boole1854"></a>
- Boole, G. (1854). An investigation of the laws of thought, on which are founded the mathematical theories of logic and probabilities. Macmillan.
<a name="brin1998"></a>
- Brin, S., & Page, L. (1998). The anatomy of a large-scale hypertextual web search engine. Computer Networks and ISDN Systems, 30(1-7), 107‚Äì117.
<a name="brown2020"></a>
- Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., ‚Ä¶ Amodei, D. (2020). Language models are few-shot learners. Advances in Neural Information Processing Systems, 33, 1877‚Äì1901.
<a name="bymycar2025"></a>
- Bymycar Webzine. (2025). Voiture autonome de niveau 5 : pour quand ?
<a name="caducee2016"></a>
- Caducee.net. (2016, November 1). Canc√©rologie : l‚ÄôIA Watson d‚ÄôIBM fait d√©j√† mieux que les m√©decins.
<a name="capek1920"></a>
- ƒåapek, K. (1920). R.U.R. (Rossum‚Äôs Universal Robots).
<a name="chen2021"></a>
- Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., & Sutskever, I. (2021). Learning transferable visual models from natural language supervision. Proceedings of the 38th International Conference on Machine Learning (ICML 2021), 139, 8748‚Äì8763. PMLR.
<a name="cheval2018"></a>
- Cheval, B., Tipura, E., Burra, N., Frossard, J., Chanal, J., Orsholits, D., Radel, R., & Boisgontier, M. P. (2018). Avoiding sedentary behaviors requires more cortical resources than avoiding physical activity: An EEG study. Neuropsychologia, 119, 68‚Äì80. https://doi.org/10.1016/j.neuropsychologia.2018.07.029
<a name="crevier1993"></a>
- Crevier, D. (1993). AI: The Tumultuous History of the Search for Artificial Intelligence. Basic Books.
<a name="devinci"></a>
- de Vinci, L. (s.d.). Codex Atlanticus.
<a name="devlin2018"></a>
- Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.
<a name="diamond1997"></a>
- Diamond, J. M. (1997). Guns, germs, and steel: The fates of human societies. W.W. Norton & Company
<a name="dondi1365"></a>
- Dondi, G. (1365‚Äì1381). Astrarium [Horloge astronomique]
<a name="freeth2021"></a>
- Freeth, T., Higgon, D., Dacanalis, A., et al. (2021). A Model of the Cosmos in the ancient Greek Antikythera Mechanism. Scientific Reports, 11, 5821. https://doi.org/10.1038/s41598-021-84310-w
<a name="friston2010"></a>
- Friston, K. (2010). The free-energy principle: a unified brain theory? Nature Reviews Neuroscience, 11(2), 127‚Äì138.
<a name="friston2016"></a>
- Friston, K., Rosch, R., Parr, T., Price, C., & Bowman, H. (2016). Deep temporal models and active inference. Neuroscience & Biobehavioral Reviews, 68, 862‚Äì879.
<a name="godel1931"></a>
- G√∂del, K. (1931). √úber formal unentscheidbare S√§tze der Principia Mathematica und verwandter Systeme I. Monatshefte f√ºr Mathematik und Physik, 38(1), 173‚Äì198.
<a name="gomez2015"></a>
- Gomez-Uribe, C. A., & Hunt, N. (2015). The Netflix recommender system: Algorithms, business value, and innovation. ACM Transactions on Management Information Systems, 6(4), Article 13.
<a name="goodfellow2014"></a>
- Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ‚Ä¶ & Bengio, Y. (2014). Generative adversarial nets. Advances in Neural Information Processing Systems, 27, 2672‚Äì2680.
<a name="google2015"></a>
- Google Inc. (2015). An update on Glass. Official Google Blog.
<a name="gowlett2016"></a>
- Gowlett, J. A. J. (2016). The discovery of fire by humans: A long and convoluted process. Philosophical Transactions of the Royal Society B: Biological Sciences, 371(1696), 20150164. https://doi.org/10.1098/rstb.2015.0164
<a name="harmand2015"></a>
- Harmand, S., Lewis, J. E., Feibel, C. S., Lepre, C. J., Roche, H., & Quinn, R. (2015). 3.3-million-year-old stone tools from Lomekwi 3, West Turkana, Kenya. Nature, 521(7552), 310‚Äì315. https://doi.org/10.1038/nature14464
<a name="heron"></a>
- H√©ron d‚ÄôAlexandrie. (s.d.). Pneumatica.
<a name="hoffman2018"></a>
- Hoffman, R. R., & Hancock, P. A. (2018). Deep learning and human factors: Tracks and applications. Human Factors, 60(8), 1171‚Äì1183.
<a name="hill1993"></a>
- Hill, D. R. (1993). Islamic science and engineering. Edinburgh University Press.
<a name="hollerith1890"></a>
- Hollerith, H. (1890). Tabulating machine for the U.S. Census [Machine √† cartes perfor√©es].
<a name="idel1990"></a>
- Idel, M. (1990). Golem: Jewish magical and mystical traditions on the artificial anthropoid. State University of New York Press
<a name="irobot2005"></a>
- iRobot Corporation. (2005). Roomba user manual. iRobot.
<a name="jaquet1775"></a>
- Jaquet-Droz, P., & Jaquet-Droz, H. (1775). Automates de Jaquet-Droz [Automates m√©caniques]
<a name="jordan2015"></a>
- Jordan, M. I., & Mitchell, T. M. (2015). Machine learning: Trends, perspectives, and prospects. Science, 349(6245), 255‚Äì260.
<a name="kahneman2011"></a>
- Kahneman, D. (2011). _Thinking, fast and slow_. Farrar, Straus and Giroux
<a name="krizhevsky2012"></a>
- Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. Advances in Neural Information Processing Systems, 25, 1097‚Äì1105.
<a name="leibniz1679"></a>
- Leibniz, G. W. (1679). Explication de l‚ÄôArithm√©tique Binaire [Manuscrit].
<a name="lemonde2025"></a>
- Le Monde. (2025). Non, les v√©hicules autonomes ne sont pas pour demain.
<a name="leroi1964"></a>
- Leroi-Gourhan, A. (1964). Le geste et la parole. Albin Michel
<a name="lewis2002"></a>
- Lewis-Williams, D. (2002). The mind in the cave: Consciousness and the origins of art. Thames & Hudson
<a name="lighthill1973"></a>
- Lighthill, J. (1973). Artificial Intelligence: A General Survey. Science Research Council.
<a name="lindblom1990"></a>
- Lindblom, B. (1990). Speaking about feelings: Conceptions of emotion across the life span. Psychology and Aging, 4(4), 517‚Äì523. https://doi.org/10.1037/0882-7974.4.4.517
<a name="llull1305"></a> 
- Llull, R. (vers 1305). Ars Magna [La Grande Art]
<a name="lovelace1843"></a>
- Lovelace, A. A. (1843). Notes sur la machine analytique de Charles Babbage.
<a name="mao2019"></a>
- Mao, J., Gan, C., Kohli, P., Tenenbaum, J. B., & Wu, J. (2019). Neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. International Conference on Learning Representations.
<a name="mccarthy1956"></a>
- McCarthy, J., Minsky, M. L., Rochester, N., & Shannon, C. E. (1956). Proposal for the Dartmouth Summer Research Project on Artificial Intelligence. Unpublished manuscript.
<a name="mcculloch1943"></a>
- McCulloch, W. S., & Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics, 5(4), 115‚Äì133.
<a name="mcdermott1982"></a>
- McDermott, J. (1982). Rl-ml: A rule-based program for configuring computer systems. Artificial Intelligence, 19(1), 39‚Äì88.
<a name="millidge2020"></a>
- Millidge, B., Tschantz, A., & Buckley, C. L. (2020). On the relationship between active inference and control as inference. Entropy, 22(4), 408.
<a name="minsky1951"></a>
- Minsky, M., & Edmonds, D. (1951). SNARC: A Neural Network Simulator. Report, MIT.
<a name="minsky1969"></a>
- Minsky, M., & Papert, S. (1969). Perceptrons. MIT Press.
<a name="newell1956"></a>
- Newell, A., & Simon, H. A. (1956). The Logic Theorist: A program that simulates the human thought process. IRE Transactions on Information Theory, 2(3), 61‚Äì79.
<a name="openai2023"></a>
- OpenAI. (2023, 14 mars). GPT-4 technical report. OpenAI. https://openai.com/research/gpt-4
<a name="oregan2001"></a>
- O‚ÄôRegan, J. K., & No√´, A. (2001). A sensorimotor account of vision and visual consciousness. Behavioral and Brain Sciences, 24(5), 939‚Äì973.
<a name="ovide"></a>
- Ovide. (s.d.). M√©tamorphoses (X, 243‚Äë297)
<a name="paletta2013"></a>
- Paletta, L., Swoboda, J., & Fritz, G. (2013). Active visual perception for human‚Äìrobot interaction. Robotics and Autonomous Systems, 61(6), 558‚Äì569.
<a name="pascal1642"></a>
- Pascal, B. (1642). La Pascaline [Machine √† calculer].
<a name="pearl1988"></a>
- Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann.
<a name="radford2018"></a>
- Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training. OpenAI.
<a name="raichle2022"></a>
- Raichle, M. E., & Gusnard, D. A. (2002). Appraising the brain‚Äôs energy budget. Proceedings of the National Academy of Sciences, 99(16), 10237‚Äì10239. https://doi.org/10.1073/pnas.172399499
<a name="ramesh2021"></a>
- Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., & Sutskever, I. (2021). Zero-shot text-to-image generation. Proceedings of the 38th International Conference on Machine Learning (ICML 2021), 139, 8821‚Äì8831. PMLR.
<a name="rosenblatt1958"></a>
- Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review, 65(6), 386‚Äì408.
<a name="rumelahart1986"></a>
- Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323(6088), 533‚Äì536.
<a name="sae2018"></a>
- SAE International. (2018). Taxonomy and definitions for terms related to driving automation systems for on-road motor vehicles (J3016_201806).
<a name="shannon1948"></a>
- Shannon, C. E. (1948). A Mathematical Theory of Communication. Bell System Technical Journal, 27(3), 379‚Äì423.
<a name="shortliffe1976"></a>
- Shortliffe, E. H. (1976). Computer-Based Medical Consultations: MYCIN. Elsevier.
<a name="stat2017"></a>
- Stat News. (2017, September 5). IBM‚Äôs Watson recommended ‚Äòunsafe and incorrect‚Äô cancer treatments, study finds.
<a name="thomas1265"></a>
- Thomas d‚ÄôAquin. (1265‚Äì1273). Summa Theologica [Somme th√©ologique]
<a name="turing1936"></a>
- Turing, A. M. (1936). On computable numbers, with an application to the Entscheidungsproblem. Proceedings of the London Mathematical Society, 2(42), 230‚Äì265.
<a name="turing1950"></a>
- Turing, A. M. (1950). Computing machinery and intelligence. Mind, 59(236), 433‚Äì460.
<a name="vaswani2017"></a>
- Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ‚Ä¶ & Polosukhin, I. (2017). Attention Is all you need. Advances in Neural Information Processing Systems, 30, 5998‚Äì6008.
<a name="vidal2018"></a>
- Vidal, M., & Piater, J. (2018). Beyond pixels: A comprehensive survey from visual recognition to cognition. Artificial Intelligence, 258, 66‚Äì115. https://doi.org/10.1016/j.artint.2018.01.004
<a name="von1945"></a>
- von Neumann, J. (1945). First Draft of a Report on the EDVAC. University of Pennsylvania.
<a name="wiener1948"></a>
- Wiener, N. (1948). Cybernetics: Or Control and Communication in the Animal and the Machine. MIT Press.
<a name="white1962"></a>
- White, L. T. Jr. (1962). Medieval technology and social change. Oxford University Press.
<a name="whitehead1910"></a>
- Whitehead, A. N., & Russell, B. (1910‚Äì1913). Principia Mathematica (Vols. I‚ÄìIII). Cambridge University Press.
<a name="wickens2008"></a>
- Wickens, C. D. (2008). Engineering psychology and human performance (4·µâ √©d.). Pearson.
<a name="wrangham2009"></a>
- Wrangham, R. (2009). Shallow-water habitats as sources of fallback foods for hominins. American Journal of Physical Anthropology, 140(4), 630‚Äì642. https://doi.org/10.1002/ajpa.21122
<a name="yarbus1967"></a>
- Yarbus, A. L. (1967). Eye Movements and Vision. Plenum Press.
<a name="yudkowsky2020"></a>
- Yudkowsky, E. (2020). Coordination problem for beneficial AI. AI Alignment Forum.